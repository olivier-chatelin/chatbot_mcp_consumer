# Code Assistant Chatbot

Application web React TypeScript avec interface Bootstrap pour un chatbot spÃ©cialisÃ© dans les conseils de code et bonnes pratiques de dÃ©veloppement, propulsÃ© par OpenAI.

## ğŸš€ FonctionnalitÃ©s

- **Support multi-LLM** : OpenAI GPT-4 ou Anthropic Claude (configurable)
- Interface chat moderne avec Bootstrap
- Conseils de code et bonnes pratiques (SOLID, sÃ©curitÃ©, performance)
- Backend Express sÃ©curisÃ© avec proxy API
- **IntÃ©gration MCP (Model Context Protocol)** : AccÃ¨s aux outils externes via votre serveur MCP
- Streaming des rÃ©ponses en temps rÃ©el
- Support Markdown avec coloration syntaxique
- Historique de conversation
- TypeScript strict sur frontend et backend

## ğŸ“‹ PrÃ©requis

- Node.js 18+
- ClÃ© API OpenAI

## âš™ï¸ Installation

1. Cloner le projet
2. Installer les dÃ©pendances :
   ```bash
   npm install
   ```

3. Configurer les variables d'environnement :
   ```bash
   # Copier le template (dÃ©jÃ  fait)
   # Ã‰diter .env et configurer votre LLM provider
   ```

4. **Choisir votre LLM provider** dans le fichier `.env` :
   
   **Pour OpenAI (GPT-4) :**
   ```
   LLM_PROVIDER=openai
   OPENAI_API_KEY=sk-...
   OPENAI_MODEL=gpt-4
   ```
   
   **Pour Anthropic (Claude) :**
   ```
   LLM_PROVIDER=anthropic
   ANTHROPIC_API_KEY=sk-ant-...
   ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
   ```

5. Configurer le chemin de votre serveur MCP dans `.env` :
   ```
   MCP_SERVER_PATH=C:\Users\chatelin\projets\POC_MCP
   ```

## ğŸƒ Utilisation

### Mode dÃ©veloppement

Lance le frontend (Vite) et le backend (Express) en parallÃ¨le :

```bash
npm run dev
```

- Frontend : http://localhost:5173
- Backend API : http://localhost:3001

### Build production

```bash
npm run build
```

### Scripts disponibles

- `npm run dev` - Lance frontend et backend en mode dÃ©veloppement
- `npm run dev:client` - Lance uniquement le frontend Vite
- `npm run dev:server` - Lance uniquement le backend Express
- `npm run build` - Build production (client + server)
- `npm run preview` - PrÃ©visualise le build client
â”œâ”€â”€ index.ts         # API endpoint /api/chat
â”‚   â”œâ”€â”€ mcp-client.ts    # Client MCP (connexion stdio)
â”‚   â”œâ”€â”€ openai-tools.ts  # Conversion outils MCP â†’ OpenAI
â”‚   â””â”€â”€ system-prompts.ts
## ğŸ“ Structure du projet

```
â”œâ”€â”€ server/              # Backend Express
â”‚   â””â”€â”€ index.ts         # API endpoint /api/chat
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/      # Composants React
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx
â”‚   â”‚   â”œâ”€â”€ MessageList.tsx
â”‚   â”‚   â”œâ”€â”€ InputArea.tsx
â”‚   â”‚   â””â”€â”€ Message.tsx
â”‚   â”œâ”€â”€ hooks/           # Hooks personnalisÃ©s
â”‚   â”‚   â””â”€â”€ useChat.ts
â”‚   â”œâ”€â”€ services/        # Services API
â”‚   â”‚   â””â”€â”€ chatService.ts
â”‚   â”œâ”€â”€ config/          # Configuration
â”‚   â”‚   â””â”€â”€ system-prompts.ts
â”‚   â”œâ”€â”€ types/           # Types TypeScript
â”‚   â”‚   â””â”€â”€ chat.types.ts
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx
â”œâ”€â”€ index.html
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ tsconfig.json
â””â”€â”€ package.json
```

## ğŸ”’ SÃ©curitÃ©

- La clÃ© API OpenAI est stockÃ©e cÃ´tÃ© backend uniquement
- Jamais exposÃ©e dans le code frontend
- RequÃªtes proxifiÃ©es via Express
, react-markdown
- **Backend** : Express, OpenAI SDK, MCP SDK
- **Build** : Vite
- **Dev tools** : tsx, concurrently

## ğŸ”Œ IntÃ©gration MCP

Le chatbot se connecte automatiquement Ã  votre serveur MCP local au dÃ©marrage. Les outils disponibles sur votre serveur MCP sont automatiquement exposÃ©s Ã  OpenAI via function calling.

**Flow :**
1. Backend dÃ©marre et se connecte au serveur MCP (stdio)
2. Liste les outils disponibles
3. Les convertit en format OpenAI function calling
4. Quand OpenAI veut utiliser un outil, le backend l'exÃ©cute via MCP
5. Le rÃ©sultat est renvoyÃ© Ã  OpenAI pour continuer la rÃ©ponse

**Configuration dans `.env` :**
- `MCP_SERVER_COMMAND` : Commande pour lancer le serveur (dÃ©faut: `node`)
- `MCP_SERVER_PATH` : Chemin vers votre serveur MCPpt, Bootstrap 5, react-bootstrap
- **Backend** : Express, OpenAI SDK
- **Build** : Vite
- **Dev tools** : tsx, concurrently

## ğŸ“ Configuration

Variables d'environnement dans `.env` :

**Provider LLM :**
- `LLM_PROVIDER` : `openai` ou `anthropic` (obligatoire)

**OpenAI (si LLM_PROVIDER=openai) :**
- `OPENAI_API_KEY` : Votre clÃ© API (obligatoire)
- `OPENAI_MODEL` : ModÃ¨le Ã  utiliser (dÃ©faut: gpt-4)
- `OPENAI_MAX_TOKENS` : Tokens max par rÃ©ponse (dÃ©faut: 5000)

**Anthropic (si LLM_PROVIDER=anthropic) :**
- `ANTHROPIC_API_KEY` : Votre clÃ© API (obligatoire)
- `ANTHROPIC_MODEL` : ModÃ¨le Ã  utiliser (dÃ©faut: claude-3-5-sonnet-20241022)
- `ANTHROPIC_MAX_TOKENS` : Tokens max par rÃ©ponse (dÃ©faut: 4096)

**Serveur :**
- `PORT` : Port du serveur backend (dÃ©faut: 3001)

**MCP :**
- `MCP_SERVER_COMMAND` : Commande pour lancer le serveur (dÃ©faut: `node`)
- `MCP_SERVER_PATH` : Chemin vers votre serveur MCP
